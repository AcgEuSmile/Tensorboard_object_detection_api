{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/intel/intelpython3/lib/python36.zip', '/opt/intel/intelpython3/lib/python3.6', '/opt/intel/intelpython3/lib/python3.6/lib-dynload', '', '/root/.local/lib/python3.6/site-packages', '/opt/intel/intelpython3/lib/python3.6/site-packages', '/opt/intel/intelpython3/lib/python3.6/site-packages/pycocotools-2.0-py3.6-linux-x86_64.egg', '/opt/intel/intelpython3/lib/python3.6/site-packages/html5lib-1.0.1-py3.6.egg', '/opt/intel/intelpython3/lib/python3.6/site-packages/pip-9.0.3-py3.6.egg', '/opt/intel/intelpython3/lib/python3.6/site-packages/IPython/extensions', '/root/.ipython', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research/slim', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research/slim', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research/slim', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research/slim', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research/slim', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research/slim', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research/slim', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research', '/workspace/yo/tensorflow_obj_detect_api/google_obj_detection/research/slim']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d79ac8702b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "print(sys.path)\n",
    "from ..lib.utility import load_config\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "\n",
    "PATH_OUTPUT = '../output_b4_with_momentum/bdd100k_test.json'\n",
    "PATH_TO_CKPT = '../output_b4_with_momentum/frozen_inference_graph.pb'\n",
    "PATH_TEST_IDS = '/workspace/datasets/BDD100k/VOC_test/ImageSets/Main/test.txt'\n",
    "DIR_IMAGE = '/workspace/datasets/BDD100k/bdd100k/images/100k/test/'\n",
    "PATH_TO_LABELS = '../label/label_map.pbtxtx'\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "def readCfg(path=\"../cfg/model_inference.json\"):\n",
    "    try:\n",
    "        with open(path, 'r') as cfg_fd:\n",
    "            json_fd = json.load(cfg_fd)\n",
    "            pathDelSlash(json_fd)\n",
    "            print(json_fd)\n",
    "            return json_fd\n",
    "    except:\n",
    "        raise(\"Config file open failed\")\n",
    "\n",
    "def pathDelSlash(json_file):\n",
    "    for i in json_file:\n",
    "        if isinstance(json_file[i], str):\n",
    "            if '/' in json_file[i]:\n",
    "                if json_file[i][-1] == '/':\n",
    "                    json_file[i] = json_file[i][:-1]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "readCfg()\n",
    "asdsd\n",
    "\n",
    "def get_results(boxes, classes, scores, category_index, im_width, im_height,\n",
    "    min_score_thresh=.2):\n",
    "    bboxes = list()\n",
    "    for i, box in enumerate(boxes):\n",
    "        if scores[i] > min_score_thresh:\n",
    "            ymin, xmin, ymax, xmax = box\n",
    "            bbox = {\n",
    "                'bbox': {\n",
    "                    'xmax': xmax * im_width,\n",
    "                    'xmin': xmin * im_width,\n",
    "                    'ymax': ymax * im_height,\n",
    "                    'ymin': ymin * im_height\n",
    "                },\n",
    "                'category': category_index[classes[i]]['name'],\n",
    "                'score': float(scores[i])\n",
    "            }\n",
    "            bboxes.append(bbox)\n",
    "    return bboxes\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "total_time = 0\n",
    "test_annos = dict()\n",
    "flag = False\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph, config=config) as sess:\n",
    "        for index, image_path in enumerate(glob.glob(DIR_IMAGE+'*.jpg')):\n",
    "            image_id = image_path.rstrip().split('/')[-1]\n",
    "            image = Image.open(image_path)\n",
    "            image_np = np.array(image).astype(np.uint8)\n",
    "            im_height, im_width, _ = image_np.shape\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            start_time = time.time()\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            end_time = time.time()\n",
    "            print('{} {} {:.3f}s'.format(time.ctime(), image_id, end_time - start_time))\n",
    "            if flag:\n",
    "                total_time += end_time - start_time\n",
    "            else:\n",
    "                flag = True\n",
    "            test_annos[image_id] = {'objects': get_results(\n",
    "                np.squeeze(boxes), np.squeeze(classes).astype(np.int32), np.squeeze(scores), category_index,\n",
    "                im_width, im_height)}\n",
    "            if index > 10:\n",
    "                break\n",
    "                \n",
    "test_annos = {'imgs': test_annos}\n",
    "fd = open(PATH_OUTPUT, 'w')\n",
    "json.dump(test_annos, fd)\n",
    "fd.close()\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
